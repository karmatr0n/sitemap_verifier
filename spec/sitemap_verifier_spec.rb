# frozen_string_literal: true

require_relative 'spec_helper'
require_relative '../sitemap_verifier'

describe HttpHelper do
  include HttpHelper

  describe '#http_get_request' do
    it 'returns a valid GET request when the argument is a valid path' do
      request = http_get_request('/example')
      expect(request).to be_a(Net::HTTP::Get)
      expect(request['User-Agent']).to be_a(String)
    end

    it 'raises an Argument error when the argument is nil' do
      expect { http_get_request(nil) }.to raise_error(ArgumentError)
    end
  end

  describe '#http_request' do
    it 'returns a valid Net::HTTP instance' do
      uri = URI.parse('http://example.com')
      http = http_request(uri)
      expect(http).to be_a(Net::HTTP)
      expect(http.address).to eq(uri.host)
      expect(http.port).to eq(uri.port)
      expect(http.use_ssl?).to eq(false)
    end

    it 'returns a valid Net::HTTP instance for HTTPS' do
      uri = URI.parse('https://example.com')
      http = http_request(uri)
      expect(http).to be_a(Net::HTTP)
      expect(http.address).to eq(uri.host)
      expect(http.port).to eq(uri.port)
      expect(http.use_ssl?).to eq(true)
      expect(http.verify_mode).to eq(OpenSSL::SSL::VERIFY_NONE)
    end
  end
end

describe SiteMapper do
  let(:example_url) { 'https://example.com/sitemap_site.xml' }

  let(:doc_xml) do
    '
        <?xml version="1.0" encoding="UTF-8"?><?xml-stylesheet type="text/xsl" href="//example.com/wp-content/plugins/wordpress-seo/css/main-sitemap.xsl"?>
        <sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
           	<sitemap>
          		<loc>https://example.com/post-sitemap.xml</loc>
          		<lastmod>2023-05-13T17:18:55+00:00</lastmod>
           	</sitemap>
           	<sitemap>
          		<loc>https://example.com.m/page-sitemap.xml</loc>
          		<lastmod>2023-05-13T17:20:21+00:00</lastmod>
           	</sitemap>
        <!-- XML Sitemap generated by Yoast SEO -->
    '
  end

  let(:doc_xml_without_loc_elements) do
    '
        <?xml version="1.0" encoding="UTF-8"?><?xml-stylesheet type="text/xsl" href="//example.com/wp-content/plugins/wordpress-seo/css/main-sitemap.xsl"?>
        <sitemapindex xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">
           	<sitemap>
          		<link>https://example.com/post-sitemap.xml</loc>
          		<lastmod>2023-05-13T17:18:55+00:00</lastmod>
           	</sitemap>
        <!-- XML Sitemap generated by Yoast SEO -->
    '
  end

  subject(:site_mapper) { SiteMapper.new(example_url) }

  describe '#map_urls' do
    let(:example_uri) { URI.parse(example_url) }
    let(:http_request) { double('Net::HTTP') }
    let(:http_get) { double('Net::HTTP::Get') }

    before do
      allow(site_mapper).to receive(:http_request).with(example_uri).and_return(http_request)
      allow(site_mapper).to receive(:http_get_request).with(example_uri.path).and_return(http_get)
    end

    it 'returns an array of urls when the response is success and include loc elements' do
      response = instance_double(Net::HTTPResponse, code: '200', body: doc_xml)
      allow(http_request).to receive(:request).with(http_get).and_return(response)
      expect(site_mapper.map_urls).to eq(['https://example.com/post-sitemap.xml', 'https://example.com.m/page-sitemap.xml'])
    end

    it 'returns an array of urls when the response is not success' do
      response = instance_double(Net::HTTPResponse, code: '500')
      allow(http_request).to receive(:request).with(http_get).and_return(response)
      expect(site_mapper.map_urls).to be_empty
    end

    it 'retries 3 times the GET request when an exception is raised' do
      allow(http_request).to receive(:request).with(http_get).exactly(3).times.and_raise(Net::OpenTimeout)
      expect(site_mapper.map_urls).to be_empty
    end
  end

  describe '#urls_from_xml' do
    it 'returns an array of urls when the loc elements exist' do
      urls = site_mapper.urls_from_xml(doc_xml)
      expect(urls).to eq(['https://example.com/post-sitemap.xml', 'https://example.com.m/page-sitemap.xml'])
    end

    it 'returns an empty array of urls when the loc elements do not exist' do
      urls = site_mapper.urls_from_xml(doc_xml_without_loc_elements)
      expect(urls).to be_empty
    end

    it 'returns an empty array of urls when xml document is not valid' do
      urls = site_mapper.urls_from_xml('invalid xml')
      expect(urls).to be_empty
    end
  end
end

describe URLChecker do
  let(:example_url) { 'https://example.com/page1' }
  let(:http_request) { double('Net::HTTP') }
  let(:http_get) { double('Net::HTTP::Get') }
  let(:example_uri) { URI.parse(example_url) }
  subject(:url_checker) { described_class.new(example_url) }

  before do
    allow(url_checker).to receive(:http_request).with(example_uri).and_return(http_request)
    allow(url_checker).to receive(:http_get_request).with(example_uri.path).and_return(http_get)
  end

  describe '#verify_status' do
    it 'gets the 200 status code when the GET request of an URL is successful' do
      response = instance_double(Net::HTTPResponse, code: '200', body: '<html><body>Hello</body></html')
      allow(http_request).to receive(:request).with(http_get).and_return(response)
      url_checker.verify_status
      expect(url_checker.status_code).to eq('200')
      expect(url_checker.url_verified).to be true
    end

    it 'gets the 500 status code when the GET request returns an error from the server' do
      response = instance_double(Net::HTTPResponse, code: '500')
      allow(http_request).to receive(:request).with(http_get).and_return(response)
      url_checker.verify_status
      expect(url_checker.status_code).to eq('500')
      expect(url_checker.url_verified).to be true
    end

    it 'retries 3 times the GET request when an exception is raised' do
      allow(http_request).to receive(:request).with(http_get).exactly(3).times.and_raise(Net::OpenTimeout)
      url_checker.verify_status
      expect(url_checker.status_code).to be_nil
      expect(url_checker.url_verified).to be false
    end
  end

  describe '#stats' do
    it 'returns the stats for the verified URL' do
      response = instance_double(Net::HTTPResponse, code: '200', body: '<html><body>Hello</body></html')
      allow(http_request).to receive(:request).with(http_get).and_return(response)
      url_checker.verify_status
      expect(url_checker.stats).to have_key(:url)
      expect(url_checker.stats).to have_key(:status_code)
      expect(url_checker.stats).to have_key(:start_time)
      expect(url_checker.stats).to have_key(:end_time)
      expect(url_checker.stats).to have_key(:duration)
      expect(url_checker.stats).to have_key(:url_verified)
    end
  end
end

describe SitemapVerifier do
  let(:example_url) { 'https://example.com/sitemap_site.xml' }
  let(:mapped_url) { 'https://example.com/pages_map.xml' }
  let(:url1) { 'https://example.com/page1' }
  let(:site_mapper1) { instance_double(SiteMapper, map_urls: [mapped_url], uri: URI.parse(example_url)) }
  let(:site_mapper2) { instance_double(SiteMapper, map_urls: [url1]) }
  let(:url_checker) { instance_double(URLChecker, verify_status: true, stats: { url: url1, url_verified: true}) }

  subject(:sitemap_verifier) { described_class.new(example_url) }

  before do
    allow(SiteMapper).to receive(:new).with(example_url).and_return(site_mapper1)
    allow(SiteMapper).to receive(:new).with(mapped_url).and_return(site_mapper2)
    allow(URLChecker).to receive(:new).with(url1).and_return(url_checker)
  end

  describe '#verify_urls' do
    it 'verifies the mapped urls and save their stats' do
      sitemap_verifier.verify_urls
      expect(sitemap_verifier.stats).to include(url_checker.stats)
    end
  end

  describe '#map_urls' do
    context 'when there are urls to map' do
      it 'maps the urls' do
        expect(sitemap_verifier.map_urls).to include(url1)
      end
    end

    context 'when there are not urls to map' do
      let!(:site_mapper2) { instance_double(SiteMapper, map_urls: []) }
      it 'returns an empty list' do
        expect(sitemap_verifier.map_urls).to be_empty
      end
    end
  end

  describe '#async_scan_urls' do
    it 'scans the mapped urls asynchronously' do
      sitemap_verifier.async_scan_urls([url1])
      expect(url_checker).to have_received(:verify_status).once
      expect(url_checker).to have_received(:stats).once
      expect(sitemap_verifier.stats).to include(url_checker.stats)
    end
  end

  describe '#save_json' do
    it 'saves the scanned urls into a json file' do
      file = instance_double(File, write: true)
      allow(File).to receive(:new).with(/^example.com.*.json$/, 'w').and_return(file)
      allow(file).to receive(:puts).with(JSON.pretty_generate([url_checker.stats]))
      allow(file).to receive(:close)
      sitemap_verifier.verify_urls
      sitemap_verifier.save_json
      expect(file).to have_received(:puts).with(JSON.pretty_generate([url_checker.stats]))
      expect(file).to have_received(:close)
    end
  end

  describe '#output_filename' do
    it 'returns the output filename' do
      expect(sitemap_verifier.output_filename).to start_with('example.com')
      expect(sitemap_verifier.output_filename).to end_with('.json')
    end
  end
end
